---
layout: single
title: 'Dataset을 이용 CSV파일에 저장된 데이터셋 로딩'
typora-root-url: ../
categories: Deeplearning_Pytorch.05.DatasetDataLoader
tag: Pytorch
toc: true
---

# Dataset을 이용해 CSV파일에 저장된 데이터셋 로딩


```python
import pandas as pd
import numpy as np
import torch 
from torch.utils.data import Dataset, DataLoader, TensorDataset
```


```python
iris = pd.read_csv('data/iris.data', header = None, names = ['꽃받침길이', '꽃받침너비', '꽃잎길이', '꽃잎너비', '정답']) # 정답-품종
iris.shape
```




    (150, 5)




```python
iris.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>꽃받침길이</th>
      <th>꽃받침너비</th>
      <th>꽃잎길이</th>
      <th>꽃잎너비</th>
      <th>정답</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
  </tbody>
</table>
</div>




```python
iris['정답'].unique()
```




    array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)




```python
index_to_class = iris['정답'].unique()
# index_to_class
class_to_index = { class_name:idx for idx, class_name in enumerate(index_to_class)}
class_to_index
```




    {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}




```python
# DataFrame -> X, y 분리
X = iris.drop(columns='정답').values # DataFrame/Series.values ==> ndarray

y = iris['정답'] 
y = y.apply(lambda x: class_to_index[x]).to_frame().values # y를 index로 변환
X.shape, y.shape
```




    ((150, 4), (150, 1))




```python
y
```




    array([[0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [0],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2],
           [2]], dtype=int64)




```python
# Train/Test set 분리
### : Python Deep Learning, Numpy배열
!pip install scikit-learn 
# (x, y) = (x1, x2), (y1, y2) 튜플
from sklearn.model_selection import train_test_split
```

    Requirement already satisfied: scikit-learn in c:\users\world\anaconda3\envs\torch\lib\site-packages (1.3.1)
    Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\users\world\anaconda3\envs\torch\lib\site-packages (from scikit-learn) (1.26.0)
    Requirement already satisfied: scipy>=1.5.0 in c:\users\world\anaconda3\envs\torch\lib\site-packages (from scikit-learn) (1.11.3)
    Requirement already satisfied: joblib>=1.1.1 in c:\users\world\anaconda3\envs\torch\lib\site-packages (from scikit-learn) (1.3.2)
    Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\world\anaconda3\envs\torch\lib\site-packages (from scikit-learn) (3.2.0)



```python
X_train, X_test, y_train, y_test = train_test_split(X, y,  # 나눌 대상 input, output
                                                    test_size = 0.2, # test 데이터셋의 비율 0.2 => train: 0.8, test: 0.2
                                                    stratify = y # 분류: 원본 데이터셋의 클래스별 데이터 비율에 맞춰서 나눈다.
                                                   )
```


```python
X.shape, X_train.shape, X_test.shape
```




    ((150, 4), (120, 4), (30, 4))




```python
y.shape, y_train.shape, y_test.shape
```




    ((150, 1), (120, 1), (30, 1))




```python
np.unique(y, return_counts=True)[1]/150
```




    array([0.33333333, 0.33333333, 0.33333333])




```python
np.unique(y_train, return_counts=True)[1]/120
```




    array([0.33333333, 0.33333333, 0.33333333])




```python
# Dataset 생성
## 원본 데이터가 메모리에 Tensor 객체(ndarray)로 있을때 => TensorDataset을 이용해서 생성.
# TensorDataset(Input:torch.Tensor, Output: torch.Tensor)

iris_trainset = TensorDataset(torch.tensor(X_train, dtype = torch.float32), # X/input
                              torch.tensor(y_train, dtype = torch.float32)  # y/output
                             )

iris_testset = TensorDataset(torch.tensor(X_test, dtype = torch.float32), 
                             torch.tensor(y_test, dtype = torch.float32)
                            )
```


```python
x, y = iris_trainset[0]
print(x)
print(y)
```

    tensor([5.9000, 3.2000, 4.8000, 1.8000])
    tensor([1.])


## torchvision.datasets.ImageFolder 이용
- 저장장치에 파일로 저장된 image들을 쉽게 로딩할 수 있도록 한다.
- train/validation/test 데이터셋을 저장하는 디렉토리에 class 별로 디렉토리를 만들고 이미지를 저장한다.


```python
# google drive의 공유파일을 다운로드 하는 라이브러리.
# !pip install gdown --upgrade
```


```python
import os
from zipfile import ZipFile
import gdown

def down_extract():
    os.makedirs('data', exist_ok=True)
    url = 'https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV'
    fname = 'data/cats_and_dogs_small.zip'

    gdown.download(url, fname, quiet=False)
    
    #zipfile모듈: Zip 압축파일을 다루는 모듈(압축하기, 풀기)
    from zipfile import ZipFile
    # 압축풀기: ZipFile(압축파일경로).extractall(풀경로) # 디렉토리 없으면 생성해 준다.
    with ZipFile(fname) as zipFile:
        zipFile.extractall(os.path.join('datasets','cats_and_dogs_small'))
        
down_extract()        
```

    Downloading...
    From (uriginal): https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV
    From (redirected): https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV&confirm=t&uuid=20f26ffd-e62c-4aec-8455-f157cfd69257
    To: C:\Users\world\Downloads\07_Deeplearning_pytorch\data\cats_and_dogs_small.zip
    100%|█████████████████████████████████████████████████████████████████████████████| 90.8M/90.8M [00:15<00:00, 5.70MB/s]



```python
# 임포트
from torchvision.datasets import ImageFolder

import torch 
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

import matplotlib.pyplot as plt
```


```python
# ImageFolder를 이용해서 Dataset을 생성.
cd_trainset = ImageFolder(root='datasets/cats_and_dogs_small/train', # 클래스별 폴더가 있는 디렉토리 설정
                          )
cd_testset = ImageFolder(root='datasets/cats_and_dogs_small/test', transform = transforms.ToTensor())
cd_validset = ImageFolder(root='datasets/cats_and_dogs_small/validation')
```


```python
isinstance(cd_trainset, Dataset)
```




    True




```python
# 데이터수
len(cd_trainset), len(cd_testset)
```




    (2000, 1000)




```python
# 데이터셋 정보
cd_trainset
```




    Dataset ImageFolder
        Number of datapoints: 2000
        Root location: datasets/cats_and_dogs_small/train




```python
# index to class
cd_trainset.classes
```




    ['cats', 'dogs']




```python
# class to index
cd_trainset.class_to_idx
```




    {'cats': 0, 'dogs': 1}




```python
x, y = cd_trainset[0]
print(y, cd_trainset.classes[y])
```

    0 cats



```python
print(type(x))
```

    <class 'PIL.Image.Image'>



```python
x
```




![output_133_0](/../../../Hinya-Github/images/2023-10-14-04.Dataset을 이용 CSV파일에 저장된 데이터셋 로딩/output_133_0-1698282093827-16.png)
    




```python
x2, y2 = cd_testset[0]
print(type(x2))
```

    <class 'torch.Tensor'>



```python
print(x2.min(), x2.max(), x2.shape)
```

    tensor(0.) tensor(1.) torch.Size([3, 500, 490])



```python
plt.imshow(x2.permute(1, 2, 0)) # [c, h, w] => [h, w, c]
```




    <matplotlib.image.AxesImage at 0x271b8f4e710>




![output_136_1](/../../../Hinya-Github/images/2023-10-14-04.Dataset을 이용 CSV파일에 저장된 데이터셋 로딩/output_136_1.png)
    

