---
layout: single
title: '데이터셋분류'
typora-root-url: ../
categories: Deeplearning_Pytorch.05.DatasetDataLoader
tag: Pytorch
toc: true
---

# 모델 성능 평가를 위한 데이터셋 분리

- **Train 데이터셋 (훈련/학습 데이터셋)**
    - 모델을 학습시킬 때 사용할 데이터셋.
- **Validation 데이터셋 (검증 데이터셋)**
    - 모델의 성능 중간 검증을 위한 데이터셋
- **Test 데이터셋 (평가 데이터셋)**
    - 모델의 성능을 최종적으로 측정하기 위한 데이터셋
    - **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용한다.**

## Validataion 과 Test datas 분리이유
- 모델을 훈련하고 평가했을때 원하는 성능이 나오지 않으면 모델을 수정한 뒤에 다시 훈련시키고 검증 하게 된다. 원하는 성능이 나올때 까지 **설정변경->훈련->검증**을 반복하게 된다. 

> - **(Parameter)머신러닝 모델 파라미터**
>    - 성능에 영향을 주는 값으로 최적화 하는 대상내는 값을 찾아야 한다.
>       - **하이퍼파라미터(Hyper Parameter)**
>            - 사람이 직접 설정해야하는 파라미터 값
>       - **파라미터(Parameter)**
>            - 데이터 학습을 통해 찾는 파라미터 값

## 파이토치 데이터셋 분리

### torch.utils.data.Subset을 이용

- Dataset의 일부를 가지는 부분집합 데이터셋을 생성
- 주로 사용하는 곳
    1. 데이터 셋을 분리
    2. 전체 데이터 셋에서 일부 데이터를 추출 할 때
    3. 데이터셋에서 특정 데이터만 골라서 추출할 때 (ex: 특정 class만 추출하는 경우)


```python
# TrainDataset과 TestDataset이 있는 경우 => ValidationDataset을 분리하려고 하는 경우
```


```python
import torch
from torchvision import datasets
from torchvision import transforms
from torch.utils.data import Subset
```


```python
data = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
label = torch.tensor([[1], [2], [2], [0], [1]])
dataset = TensorDataset(data, label)
len(dataset)
```


```python
d1 = Subset(dataset, [0, 1]) # data의 index 0, 1을 d1으로
# dataset의 input/output중 0, 1 index의 값들로 부분 집합 Dataset 생성

d2 = Subset(dataset, [2, 3, 4]) # data의 index 2, 3, 4을 d2로 나누기.

```


```python
print(type(d1), isinstance(d1, Dataset))
print(len(d1), len(d2))
```

    <class 'torch.utils.data.dataset.Subset'> True
    2 3



```python
d1[0]
```




    (tensor([1, 2]), tensor([1]))




```python
d2[0]
```




    (tensor([5, 6]), tensor([2]))




```python
DATA_ROOT_PATH = 'datasets'

mnist_trainset = datasets.MNIST(root=DATA_ROOT_PATH, train=True, download=True, transform=transforms.ToTensor())
```


```python
len(mnist_trainset)
```




    60000




```python
# mnist_trainset -> trainset, validation set
t_index = list(range(50000))
v_index = list(range(50000, 60000))
t_set = Subset(mnist_trainset, t_index)
v_set = Subset(mnist_trainset, v_index)
len(t_set), len(v_set)
```




    (50000, 10000)



### random_split() 함수 이용

- Dataset객체와 나눌 데이터셋들의 원소개수를 리스트로 묶어서 전달하면  Shuffle후 나눈뒤 그 결과를 Subset객체들을 리스트에 담아 반환한다.


```python
import torch
from torchvision import datasets
from torchvision import transforms
from torch.utils.data import Subset
from torch.utils.data import random_split # 함수
```


```python
data = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
label = torch.tensor([[1], [2], [2], [0], [1]])
dataset = TensorDataset(data, label)
```


```python
len(dataset)
```




    5




```python
# dataset(5개) -> 2 (3개 2개)
d = random_split(dataset, # 나눌대상 Dataset
                 [2, 3] # 개수를 지정.
            )
d
```




    [<torch.utils.data.dataset.Subset at 0x271bb3e0fd0>,
     <torch.utils.data.dataset.Subset at 0x271bb3e0820>]




```python
len(d[0]), len(d[1])
```




    (2, 3)




```python
for x, y in dataset:
    print(x)
```

    tensor([1, 2])
    tensor([3, 4])
    tensor([5, 6])
    tensor([7, 8])
    tensor([ 9, 10])



```python
for x, y in d[0]:
    print(x)
```

    tensor([1, 2])
    tensor([5, 6])



```python
random_split(dataset, [1, 2, 2]) # 3개 Subset으로 나눔
```




    [<torch.utils.data.dataset.Subset at 0x271b82d0c40>,
     <torch.utils.data.dataset.Subset at 0x271b82d0b20>,
     <torch.utils.data.dataset.Subset at 0x271b82d2830>]




```python
# mnist_trainset -> 두개 dataset으로 나눌경우 => 개수
mnist_trainset, mnist_valset = random_split(mnist_trainset, [50000, 10000])
```


```python
len(mnist_trainset), len(mnist_valset)
```




    (50000, 10000)

