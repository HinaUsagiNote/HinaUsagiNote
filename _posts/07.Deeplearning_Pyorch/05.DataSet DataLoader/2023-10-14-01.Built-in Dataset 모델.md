---
layout: single
title: 'Built-in Dataset 모델'
typora-root-url: ../
categories: Deeplearning_Pytorch.05.DatasetDataLoader
tag: Pytorch
toc: true
---

# Dataset 과 DataLoader

- 딥러닝 모델을 학습시키고 평가할때 사용할 데이터를 제공하기 위한 객체
- **torch.utils.data.Dataset**
    - 원본 데이터셋(input/output dataset)을 저장하고 있으며 indexing을 통해 데이터를 하나씩 제공한다.
- **torch.utils.data.DataLoader**
    - Dataset의 데이터를 batch단위로 모델에 제공하기 위한 객체.

# Built-in Dataset

- 파이토치는 분야별 공개 데이터셋을 종류별로 torchvision, torchtext, torchaudio 모듈을 통해 제공한다.
- 모든 built-in dataset은 [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)의 하위클래스로 구현되있다.

## Image  Built-in dataset Loading
torchvision 모듈을 통해 다양한 오픈소스 이미지 데이터셋을 loading할 수 있는 Dataset 클래스를 제공한다.

- 각 Dataset 클래스의 주요 매개변수
    - **root**: str
        - Raw data를 저장할 디렉토리 경로
    - **train**: bool
        - True일경우 Train set을 False일 경우 Test set을 load
    - **download**: bool
        - True이면 root에 지정된 경로에 raw 데이터를 인터셋에서 download할지 여부. 
    - **transform**: function
        - Loading한 이미지를 변환하는 function.
            - Normalization이나 data Agumentation 처리를 한다.
            


```python
import torch
import torch.nn as nn
from torchvision import datasets # torcchvision(파이토치 영상처리 모듈).datasets(이미지 데이터셋 제공 클래스)

import numpy as np
import matplotlib.pyplot as plt
```


```python
# 데이터들을 저장할 디렉토리
DATASET_ROOT_PATH = 'datasets' # 상대경로, 절대경로 상관없음
```


```python
# MNIST Dataset 생성
## Train dataset
mnist_trainset = datasets.MNIST(root = DATASET_ROOT_PATH, # 원본데이터파일들을 저장된 위치.
                                train = True,             # True: Train Set, False: Test Set
                                download = True           # True: 원본파일이 없으면 다운로드, False: 다운받지 않는다.
                                # transfroms = 이미지변환처리함수 # 이미지를 제공하기 전에 전처리할 함수
)
```


```python
# MNIST Dataset 생성
## Test dataset -> train = False
mnist_testset = datasets.MNIST(root = DATASET_ROOT_PATH, train = False, download = True)
```


```python
# 타입확인
print(type(mnist_trainset), type(mnist_testset))
## Dataset의 하위클래스의 겍치인지(상속관계)
print(isinstance(mnist_trainset, torch.utils.data.Dataset)) # isinstance(객체, 클래스): 객체가 클래스 타입의 객치인지 확인. 보통 상속관계를 확인
```

    <class 'torchvision.datasets.mnist.MNIST'> <class 'torchvision.datasets.mnist.MNIST'>
    True



```python
# Bulit-in Dataset 정보 확인
print(mnist_trainset)
print('='*35)
print(mnist_testset)
```

    Dataset MNIST
        Number of datapoints: 60000
        Root location: datasets
        Split: Train
    ===================================
    Dataset MNIST
        Number of datapoints: 10000
        Root location: datasets
        Split: Test



```python
# 총 데이터의 개수만 확인
print(len(mnist_trainset), len(mnist_testset))
```

    60000 10000



```python
# Dataset은 subscriptable 타입 (indexing이 가능)이다 => indexing으로 개별 데이터 조회가 가능(Dataset은 slicing/fancy indexing은 안됨 => 한개씩 조회가능)
data1 = mnist_trainset[0]
print(type(data1)) # Tuple: (input, output)
print(type(data1[0]), type(data1[1]))
```

    <class 'tuple'>
    <class 'PIL.Image.Image'> <class 'int'>



```python
print(data1[1])

data1[0]
```

    5




![output_12_1](/../../images/2023-10-14-01.Built-in Dataset 모델/output_12_1.jpg)
    




```python
# data1 의 ndarray 변환
img1 = np.array(data1[0])
print(img1.shape, img1.min(), img1.max())
```

    (28, 28) 0 255


이미지 시각화


```python
plt.imshow(img1, cmap='gray')
plt.show()
```


![output_15_0](/../../images/2023-10-14-06.Dataset과 DataLoader/output_15_0.png)
    



```python
# 이미지 여러개 확인
for i in range(15):
    plt.subplot(3, 5, i+1)
    img, label = mnist_trainset[i] # 튜플대입
    img = np.array(img) # PIL.Image -> ndarray
    plt.imshow(img, cmap='gray')
    plt.title(str(label)) # label: int -> 문자열로 변환.

plt.tight_layout()
plt.show()
```


![output_16_0](/../../images/2023-10-14-06.Dataset과 DataLoader/output_16_0.png)
    



```python
# Output의 범주값(Class)들 확인 -> MNIST는 분류문제를 위한 데이터. 분류문제: y가 범주형(contegorical type)
mnist_trainset.classes
# list: index-클래스, value: 정답의 의미 문자열.
# 0 : '0 - zero' # 정답: 0 => 0의 의미: 0 - zero
```




    ['0 - zero',
     '1 - one',
     '2 - two',
     '3 - three',
     '4 - four',
     '5 - five',
     '6 - six',
     '7 - seven',
     '8 - eight',
     '9 - nine']




```python
mnist_trainset.class_to_idx
# 정답의미 -> class: 딕셔너리
```




    {'0 - zero': 0,
     '1 - one': 1,
     '2 - two': 2,
     '3 - three': 3,
     '4 - four': 4,
     '5 - five': 5,
     '6 - six': 6,
     '7 - seven': 7,
     '8 - eight': 8,
     '9 - nine': 9}




```python
pred_label = 3 # 모델이 추정한 값으로 가정.
mnist_trainset.classes[pred_label]
```




    '3 - three'




```python
mnist_trainset.class_to_idx['3 - three'] # '3 - three' 을 모델이 어떤 값으로 추정하는지.
```




    3




### transform 매개변수를 이용한 데이터전처리
- Dataset 생성할 때 전달하는 함수로 원본데이터를 모델에 주입(feeding)하기 전 **전처리 과정을 정의한다.**
    - Data Pipeline을 구성하는 함수
- 매개변수로 input data 한개를 입력받아 처리한 결과를 반환하도록 구현한다.


```python
import torch
import torch.nn as nn
from torchvision import datasets # torcchvision(파이토치 영상처리 모듈).datasets(이미지 데이터셋 제공 클래스)
from torchvision import transforms

import numpy as np
```


```python
mnist_trainset1 = datasets.MNIST(root = DATASET_ROOT_PATH, train = True, download = True)
mnist_testset1 = datasets.MNIST(root = DATASET_ROOT_PATH, train = False, download = True)
```


```python
data = mnist_trainset[0][0]
img = np.array(data)
print('data의 type:', type(data))
print('image의 shape:', img.shape)
print('pixcel 최소, 최대값 -', img.min(), img.max())
print('dtype(픽셀값의 타입):',img.dtype)
```

    data의 type: <class 'PIL.Image.Image'>
    image의 shape: (28, 28)
    pixcel 최소, 최대값 - 0 255
    dtype(픽셀값의 타입): uint8


### torchvision.transforms.ToTensor
 -  PIL Image나 NumPy ndarray 를 FloatTensor(float32) 로 변환하고, 이미지의 픽셀의 크기(intensity) 값을 \[0., 1.\] 범위로 비례하여 조정한다.
 - Image 의 shape을 (channel, height, width) 로 변경한다.


```python
# transform 이 설정안된 경우: 원본이미지파일 - 읽어서 -> Dataset - 반환
#             　설정된 경우: 원본이미지 -읽어서 -> Dataset-transform함수(이미지) - 반환
mnist_trainset2 = datasets.MNIST(root=DATASET_ROOT_PATH, train=True, download=True,
                                 transform=transforms.ToTensor() # ToTensor  클래스 객체
                                )
```


```python
data2, label = mnist_trainset2[0]
print(label)
```

    5



```python
print('data2의 타입:', type(data2)) # PIL.Image -> Tensor
print(data2.shape)                 # [channel, height, width] 
print('pixcel의 최소, 최대값:', data2.min(), data2.max()) # 0 ~ 1 사이 정규화(normalize) ==> scaling
print('dtype(픽셀값의 타입):',data2.dtype) # uint 8 -> float32 
```

    data2의 타입: <class 'torch.Tensor'>
    torch.Size([1, 28, 28])
    pixcel의 최소, 최대값: tensor(0.) tensor(1.)
    dtype(픽셀값의 타입): torch.float32


### transform.Normalize
- 채널별로 지정한 평균을 뺀 뒤 지정한 표준편차로 나누어서 정규화를 진행한다.
- ToTensor()로 변환된 데이터를 받아서 추가 변환
        - 여려 변환을 할 경우 `torchvision.transforms.Compose` 클래스를 이용한다.


```python
import torch
import torch.nn as nn
from torchvision import datasets # torcchvision(파이토치 영상처리 모듈).datasets(이미지 데이터셋 제공 클래스)
from torchvision import transforms
```


```python
# 여러개의 transform 함수들을 묶어서 순서대로 호출 -> Compose()를 이용해서 묶어준다
## 리스트에 호출 될 순서대로 넣어서 전달.

### ToTensor() -> NMormalize()
transform = transforms.Compose([transforms.ToTensor(), # 첫번째 작업
                                transforms.Normalize(mean=0.5, std=0.5) # 첫번째 변화작업결과를 받아서 두번째 변환
                               ])
```


```python
mnist_trainset3 = datasets.MNIST(root=DATASET_ROOT_PATH, train=True, download=True, transform=transform)
mnist_testset3 = datasets.MNIST(root=DATASET_ROOT_PATH, train=False, download=True, transform=transform)
```


```python
img3, label3 = mnist_trainset3[0]
print(type(img3))
print(img3.shape)
print(img3.dtype)

print(img3.min(), img3.max())
```

    <class 'torch.Tensor'>
    torch.Size([1, 28, 28])
    torch.float32
    tensor(-1.) tensor(1.)



```python
# channel이 여러개인 경우(color-3): mean/std = 값 => 모든 채널에 공통적으로 사용할 평균/표준편차 설정.
#                                 mean/std = 튜플 => 각 채널별로 적용할 값을 튜플에 각각 넣어준다.
# normalizer = transforms.Normalize(mean = 0.5, std = 0.5) # 모든 픽셀에 평균=0.5, 표준편차=0.5 로 계산.

normalizer = transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # Channel, height, width
transform2 = transforms.Compose([transforms.ToTensor(), normalizer])
```


```python
cifar_trainset2 = datasets.CIFAR10(root=DATASET_ROOT_PATH, train=True, download=True, transform=transform2)
```

    Files already downloaded and verified



```python
# mean/std = 튜플 각 채널별로 적용
img4, label4 = cifar_trainset2[0]
print(img4.shape)
print('Red Channel의 min/max:', img4[0].min(), img4[0].max())
print('Green Channel의 min/max:', img4[1].min(), img4[1].max())
print('Blue Channel의 min/max:', img4[2].min(), img4[2].max())
```

    torch.Size([3, 32, 32])
    Red Channel의 min/max: tensor(-2.1179) tensor(2.2489)
    Green Channel의 min/max: tensor(-2.0357) tensor(2.3936)
    Blue Channel의 min/max: tensor(-1.8044) tensor(2.2914)


## DataLoader 생성

- DataLoader
    - 모델이 학습하거나 추론할 때 Dataset의 데이터를 모델에 제공해준다. (feeding)
    - initalizer속성
        - dataset: 값을 제공하는 Dataset 타입 객체
        - batch_size: 한번에 값을 제공할 batch 크기
        - shuffle: 에폭마다 데이터셋을 섞을 지 여부 (default: False)
        - drop_last: 마지막 배치의 데이터개수가 batch_size 설정보다 적을 경우 모델에 제공하지 않는다.



```python
import torch
import torch.nn as nn
from torchvision import datasets 
from torch.utils.data import DataLoader
from torchvision import transforms
```


```python
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=0.5, std=0.5)])
```


```python
mnist_trainset3 = datasets.MNIST(root=DATASET_ROOT_PATH, train=True, download=True, transform=transform)
mnist_testset3 = datasets.MNIST(root=DATASET_ROOT_PATH, train=False, download=True, transform=transform)
```


```python
# mnist_xxx_3 (transform=ToTensor+Normalize)
mnist_train_loader = DataLoader(dataset= mnist_trainset3, # 데이터를 제공받을 Dataset
                                batch_size=200,           # 한번에 제공할 데이터 개수 
                                shuffle=True,             # 처음제공전에 데이터들을 섞을지 여부 - Trainset: Ture, Testset: False
                                drop_last=True)           # 제공할 데이터개수가 batch_size보다 적을 경우 제공할지 여부(True: 제공안함.) - Trainset: Ture, Testset: False
mnist_test_loader = DataLoader(dataset = mnist_testset3, batch_size=200)
```


```python
# DataLoader -> Iterable 타입 (반복문)
## 에폭당 step 수 조회
### drop last=True: floor(총데이터수/barch_size), False: ceil(총데이터수/barch_size)
print(len(mnist_train_loader), len(mnist_test_loader))
```

    300 50



```python
# DataLoader에 설정된 Dataset을 조회.
mnist_train_loader.dataset
```




    Dataset MNIST
        Number of datapoints: 60000
        Root location: datasets
        Split: Train
        StandardTransform
    Transform: Compose(
                   ToTensor()
                   Normalize(mean=0.5, std=0.5)
               )




```python
mnist_train_loader.batch_size
```




    200




```python
# DataLaoder에서 데이터를 조회 -> Iterable타입 ==> 한번: iter(): Iterator, next(iterator), 다: for in
batch1 = next(iter(mnist_train_loader))
```


```python
print(type(batch1), len(batch1)) # [input들, output들]
```

    <class 'list'> 2



```python
X, y = batch1
print(type(X), type(y))
# 원본 -> ToTensor, Normalize, X(학습데이터): 200, y(정답): 200
```

    <class 'torch.Tensor'> <class 'torch.Tensor'>



```python
print(X.shape) # [200: batch_size, 1: channel->gray, 28:height, 28: width]
print(y.shape) # [200: batch_size]
```

    torch.Size([200, 1, 28, 28])
    torch.Size([200])


## Custom Dataset 구현

1. `torch.utils.data.Dataset` 클래스를 상속한 클래스를 정의한다.
2. `__init__(self, ...)` 
    - DataSet객체 생성시 필요한 설정들을 초기화 한다. 
3. `__len__(self)`
    - 총 데이터 수를 반환하도록 구현한다.
    - DataLoader가 Batch 생성할 때 사용한다.
4. `__getitem__(self, index)`
    - index의 Data point를 반환한다.
    - input(X), output(y) 를 튜플로 반환한다.
    - transform이 있을 경우 변환처리한 input을 반환한다.


```python
# subscriptable 타입 클래스 구현 -> indexing 가능객체
class MySub:

    def __init__(self):
        # 제공할 값들을 초기화
        self.one = '사자'
        self.two = '호랑이'
        self.three = '하마'

    def __len__(self):
        # 제공할 데이터의 개수를 반환.
        return 3

    def __getitem__(self, idx):
        # idx의 값을 반환.
        if idx == 0:
            return self.one
        elif idx == 1:
            return self.two
        elif idx == 2:
            return self.three
        else:
            raise IndexError(f"{idx}번째 값이 없습니다.")
```


```python
m = MySub()
len(m) # m.__len__(): 호출
```




    3




```python
len(mnist_testset)
```




    10000




```python
m[0], m[1], m[2]
```




    ('사자', '호랑이', '하마')




```python
mnist_testset[0][0]
```




![output_67_0](/../../images/2023-10-14-06.Dataset과 DataLoader/output_67_0.jpg)
    




```python
m[10]
```


    ---------------------------------------------------------------------------
    
    IndexError                                Traceback (most recent call last)
    
    Cell In[69], line 1
    ----> 1 m[10]


    Cell In[63], line 23, in MySub.__getitem__(self, idx)
         21     return self.three
         22 else:
    ---> 23     raise IndexError(f"{idx}번째 값이 없습니다.")


    IndexError: 10번째 값이 없습니다.

